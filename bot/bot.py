import logging
import os
import aiofiles
from io import BytesIO
from PIL import Image
from pydub import AudioSegment
import asyncio

from telegram import Update, InputFile
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes

import openai
import whisper
from transformers import BlipProcessor, BlipForConditionalGeneration
import torch

# --------- ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªÙˆÚ©Ù† Ù‡Ø§ ----------
TELEGRAM_TOKEN = '8204535470:AAFQ7ffXUy2jDyj79phxDq4RwdwPeweWrJg'
OPENROUTER_API_KEY = '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'

# ØªÙ†Ø¸ÛŒÙ… Ú©Ù„ÛŒØ¯ OpenRouter Ø¯Ø± Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ openai
openai.api_key = OPENROUTER_API_KEY

# --------- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ ------------

# Ù…Ø¯Ù„ Whisper (ØªØ¨Ø¯ÛŒÙ„ ÙˆÛŒØ³ Ø¨Ù‡ Ù…ØªÙ†)
whisper_model = whisper.load_model("base")  # Ù†Ø³Ø®Ù‡ Ø³Ø¨Ú©Ø› Ø§Ú¯Ø± Ø³Ø±ÙˆØ±Øª Ù‚ÙˆÛŒ Ø§Ø³Øª "small" ÛŒØ§ "medium" Ù‡Ù… Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ø±Ø¯

# Ù…Ø¯Ù„ BLIP (ØªØ­Ù„ÛŒÙ„ Ùˆ ØªÙˆØµÛŒÙ ØªØµÙˆÛŒØ±)
device = "cuda" if torch.cuda.is_available() else "cpu"
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
blip_model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base").to(device)

# --------- ØªÙ†Ø¸ÛŒÙ… Ù„Ø§Ú¯ ---------
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO
)
logger = logging.getLogger(__name__)

# --------- Ù¾Ø±Ø§Ù…Ù¾Øª Ø³ÛŒØ³ØªÙ… Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø­ÙˆØ²Ù‡ (Ø²ÛŒØ³Øª Ùˆ Ù¾Ø²Ø´Ú©ÛŒ) ---------
SYSTEM_PROMPT = (
    "Ø´Ù…Ø§ Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ ÙÙ‚Ø· Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø²ÛŒØ³Øªâ€ŒØ´Ù†Ø§Ø³ÛŒØŒ Ù¾Ø²Ø´Ú©ÛŒØŒ Ø¹Ù„ÙˆÙ… ØªØ¬Ø±Ø¨ÛŒ Ùˆ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ø¹Ù„Ù…ÛŒ Ù¾Ø§Ø³Ø® Ù…ÛŒâ€ŒØ¯Ù‡ÛŒØ¯."
    " Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ Ø®Ø§Ø±Ø¬ Ø§Ø² Ø§ÛŒÙ† Ø­ÙˆØ²Ù‡ Ø¨Ø§Ø´Ø¯ØŒ Ù…ÙˆØ¯Ø¨Ø§Ù†Ù‡ Ø§Ø¹Ù„Ø§Ù… Ú©Ù†ÛŒØ¯ Ú©Ù‡ ÙÙ‚Ø· Ø¯Ø± Ø§ÛŒÙ† Ø­ÙˆØ²Ù‡â€ŒÙ‡Ø§ Ù¾Ø§Ø³Ø®Ú¯Ùˆ Ù‡Ø³ØªÛŒØ¯."
)

# --------- ØªØ§Ø¨Ø¹ Ù¾Ø±Ø³Ø´ Ø¨Ù‡ OpenRouter ----------
async def ask_openrouter(question: str) -> str:
    try:
        response = await openai.ChatCompletion.acreate(
            model="gpt-3.5-turbo",  # ÛŒØ§ Ù…Ø¯Ù„ÛŒ Ú©Ù‡ ØªÙˆÚ©Ù† ØªÙˆ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": question}
            ],
            max_tokens=500,
            temperature=0.7,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"OpenRouter API error: {e}")
        return "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù… Ø¨Ù‡ Ø³ÙˆØ§Ù„ Ø´Ù…Ø§ Ù¾Ø§Ø³Ø® Ø¯Ù‡Ù…."

# --------- ØªØ¨Ø¯ÛŒÙ„ ÙˆÛŒØ³ Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ Whisper ---------
async def transcribe_audio(file_path: str) -> str:
    result = whisper_model.transcribe(file_path)
    return result["text"]

# --------- ØªØ­Ù„ÛŒÙ„ ØªØµÙˆÛŒØ± Ø¨Ø§ BLIP ----------
async def analyze_image(image_bytes: bytes) -> str:
    try:
        image = Image.open(BytesIO(image_bytes)).convert('RGB')
        inputs = processor(image, return_tensors="pt").to(device)
        out = blip_model.generate(**inputs)
        caption = processor.decode(out[0], skip_special_tokens=True)
        return caption
    except Exception as e:
        logger.error(f"BLIP image analysis error: {e}")
        return "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù†ØªÙˆØ§Ù†Ø³ØªÙ… ØªØµÙˆÛŒØ± Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†Ù…."

# --------- Ù‡Ù†Ø¯Ù„Ø± Ø´Ø±ÙˆØ¹ /start ---------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text(
        "Ø³Ù„Ø§Ù…! Ù…Ù† Ø±Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù‡Ø³ØªÙ…. Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø§Ø² Ù…Ù† Ø³ÙˆØ§Ù„ Ø¨Ù¾Ø±Ø³ÛŒØ¯ØŒ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯ ØªØ§ Ù…ØªÙ†Ø´ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³Ù…ØŒ ÛŒØ§ ØªØµÙˆÛŒØ± Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯ ØªØ§ Ø¢Ù† Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†Ù…."
    )

# --------- Ù‡Ù†Ø¯Ù„Ø± Ù¾ÛŒØ§Ù… Ù…ØªÙ†ÛŒ ---------
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_text = update.message.text
    user_id = update.message.from_user.id
    logger.info(f"Received text from {user_id}: {user_text}")

    response_text = await ask_openrouter(user_text)
    await update.message.reply_text(response_text)

# --------- Ù‡Ù†Ø¯Ù„Ø± ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ---------
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    voice = update.message.voice
    user_id = update.message.from_user.id
    logger.info(f"Received voice from {user_id}")

    # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
    file = await context.bot.get_file(voice.file_id)
    file_path = f"voice_{user_id}.ogg"
    await file.download_to_drive(file_path)

    # ØªØ¨Ø¯ÛŒÙ„ ogg Ø¨Ù‡ wav Ø¨Ø§ pydub
    wav_path = f"voice_{user_id}.wav"
    audio = AudioSegment.from_ogg(file_path)
    audio.export(wav_path, format="wav")

    # ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ†
    transcription = await transcribe_audio(wav_path)

    # Ø­Ø°Ù ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØµØ±ÙÙ‡â€ŒØ¬ÙˆÛŒÛŒ Ø¯Ø± ÙØ¶Ø§
    os.remove(file_path)
    os.remove(wav_path)

    # Ù¾Ø§Ø³Ø® Ù…ØªÙ† ØªØ¨Ø¯ÛŒÙ„ Ø´Ø¯Ù‡
    await update.message.reply_text(f"Ù…ØªÙ† Ú¯ÙØªØ§Ø± Ø´Ù…Ø§:\n{transcription}")

# --------- Ù‡Ù†Ø¯Ù„Ø± Ø¹Ú©Ø³ ---------
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_id = update.message.from_user.id
    logger.info(f"Received photo from {user_id}")

    photo = update.message.photo[-1]  # Ø¨Ø§ Ú©ÛŒÙÛŒØª ØªØ±ÛŒÙ† Ø¹Ú©Ø³
    file = await context.bot.get_file(photo.file_id)
    bio = BytesIO()
    await file.download(out=bio)
    bio.seek(0)

    caption = await analyze_image(bio.read())
    await update.message.reply_text(f"ØªÙˆØ¶ÛŒØ­ ØªØµÙˆÛŒØ±:\n{caption}")

# --------- Ù‡Ù†Ø¯Ù„Ø± ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ ---------
async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_id = update.message.from_user.id
    logger.info(f"Received document from {user_id}")

    doc = update.message.document
    file = await context.bot.get_file(doc.file_id)
    file_path = f"document_{user_id}_{doc.file_name}"
    await file.download_to_drive(file_path)

    # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ (Ù…Ø«Ù„Ø§Ù‹ txt)
    try:
        async with aiofiles.open(file_path, mode='r', encoding='utf-8') as f:
            content = await f.read()
    except Exception as e:
        logger.error(f"Error reading document: {e}")
        content = "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ù†ØªÙˆØ§Ù†Ø³ØªÙ… ÙØ§ÛŒÙ„ Ø±Ø§ Ø¨Ø®ÙˆØ§Ù†Ù…."

    os.remove(file_path)
    # Ø§Ø±Ø³Ø§Ù„ Ù…Ø­ØªÙˆØ§ Ø¨Ù‡ Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® (Ù…Ø«Ù„Ø§Ù‹ Ø®Ù„Ø§ØµÙ‡ ÛŒØ§ Ø³ÙˆØ§Ù„)
    response_text = await ask_openrouter(content)
    await update.message.reply_text(f"Ù…Ø­ØªÙˆØ§ÛŒ ÙØ§ÛŒÙ„:\n{response_text}")

# --------- ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ----------
async def main():
    application = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    application.add_handler(MessageHandler(filters.VOICE, handle_voice))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    application.add_handler(MessageHandler(filters.Document.ALL, handle_document))

    print("ğŸ¤– Ø±Ø¨Ø§Øª Ø´Ù…Ø§ ÙØ¹Ø§Ù„ Ø´Ø¯!")
    await application.run_polling()

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
